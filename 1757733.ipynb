{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简介\n",
    "本项目是参加飞桨常规赛：中文场景文字识别（已结束）的项目，项目score为85.87141。\n",
    "\n",
    "生成的预测文件为work/PaddleOCR中的test2.txt文件\n",
    "\n",
    "项目任务为识别包含中文文字的街景图片，准确识别图片中的文字\n",
    "\n",
    "本项目源于https://aistudio.baidu.com/aistudio/projectdetail/681670，在此基础上进行修改\n",
    "\n",
    "感谢开发者为开源社区做出的贡献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 本方案在最终测试得到的分数\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/be1f8b3ca96946289249566d56905117e162fc6824e848618a41ec1a112a73fd)\n",
    "\n",
    "\n",
    "\n",
    "比原作者提供最优的方案略有涨点，并且实现了正确输出结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 赛题说明\n",
    "**赛题背景**\n",
    "\n",
    "中文场景文字识别技术在人们的日常生活中受到广泛关注，具有丰富的应用场景，如：拍照翻译、图像检索、场景理解等。然而，中文场景中的文字面临着包括光照变化、低分辨率、字体以及排布多样性、中文字符种类多等复杂情况。如何解决上述问题成为一项极具挑战性的任务。\n",
    "\n",
    "本次飞桨常规赛以 中文场景文字识别 为主题，由2019第二届中国AI+创新创业全国大赛降低难度而来，提供大规模的中文场景文字识别数据，旨在为研究者提供学术交流平台，进一步推动中文场景文字识别算法与技术的突破。\n",
    "\n",
    "**比赛任务**\n",
    "\n",
    "要求选手必须使用飞桨对图像区域中的文字行进行预测，返回文字行的内容。\n",
    "\n",
    "**数据集介绍**\n",
    "\n",
    "本次竞赛数据集共包括33万张图片，其中21万张图片作为训练集，12万张作为测试集。数据集采自中国街景，并由街景图片中的文字行区域（例如店铺标牌、地标等等）截取出来而形成。所有图像都经过一些预处理，将文字区域利用仿射变化，等比映射为一张高为48像素的图片，如下图1所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fb3cf59747e04f0cb9adde6a5a1945b3d9ef82f3b7c14c98bf248eb1c3886a3f)\n",
    "\n",
    "\n",
    "(a) 标注：魅派集成吊顶\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/57d58a35e1f34278bdb013b3f945ab69cddacf37c7fe40deba3c124fa1249753)\n",
    "\n",
    "\n",
    "(b) 标注：母婴用品连锁\n",
    "图1\n",
    "\n",
    "**标注文件**\n",
    "\n",
    "平台提供的标注文件为.txt文件格式。样例如下：\n",
    "\n",
    "\n",
    "\n",
    "| h | w | name | value |\n",
    "| -------- | -------- | -------- |-------- |\n",
    "| 128 | 48 | img_1.jpg | 文本1|\n",
    "| 56\t| 48\t| img_2.jpg|\t文本2|\n",
    "其中，文件中的四列分别是图片的宽、高、文件名和文字标注。\n",
    "\n",
    "**比赛重点：**\n",
    "准确识别图片的文字，提升准确率\n",
    "\n",
    "**比赛难点：**\n",
    "准确识别并且把输出结果正确输入文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 安装第三方库\n",
    "\n",
    "将安装目录设置为external-libraries，这样项目重启后安装的库不会消失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/aistudio/external-libraries’: File exists\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.36.1)\n",
      "Collecting paddlepaddle-gpu==1.7.1.post97\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/31/b0/54f9450eb71a23aad0edf69d52423529a09dcc4c0ffa650ff5ba1feb0572/paddlepaddle_gpu-1.7.1.post97-cp37-cp37m-manylinux1_x86_64.whl (251.6MB)\n",
      "\u001b[K     |████████████████████████████████| 251.6MB 140kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.10.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (6.2.0)\n",
      "Requirement already satisfied: objgraph in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.4.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (2.22.0)\n",
      "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (2.2.3)\n",
      "Requirement already satisfied: scipy<=1.3.1; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.3.0)\n",
      "Requirement already satisfied: graphviz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (0.13)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (5.1.2)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.1)\n",
      "Requirement already satisfied: numpy>=1.12; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.16.4)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (4.4.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (4.1.1.26)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (0.7.2)\n",
      "Requirement already satisfied: nltk; python_version >= \"3.5\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (3.4.5)\n",
      "Requirement already satisfied: funcsigs in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.0.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlepaddle-gpu==1.7.1.post97) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from protobuf>=3.1.0->paddlepaddle-gpu==1.7.1.post97) (41.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle-gpu==1.7.1.post97) (2.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2.4.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib; python_version >= \"3.6\"->paddlepaddle-gpu==1.7.1.post97) (2019.3)\n",
      "Installing collected packages: paddlepaddle-gpu\n",
      "  Found existing installation: paddlepaddle-gpu 1.6.2.post97\n",
      "    Uninstalling paddlepaddle-gpu-1.6.2.post97:\n",
      "      Successfully uninstalled paddlepaddle-gpu-1.6.2.post97\n",
      "Successfully installed paddlepaddle-gpu-1.7.1.post97\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple/\n",
      "Collecting pqi\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/33/a0/c446aed3d2a2aee6603baa430979c402859821a9bf02c23f59500171c9d2/pqi-2.0.6.tar.gz\n",
      "Collecting docopt (from pqi)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Building wheels for collected packages: pqi, docopt\n",
      "  Building wheel for pqi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pqi: filename=pqi-2.0.6-cp37-none-any.whl size=4442 sha256=d3d36fa0ffd99e668dcd11502f9672d891c60fd757c72c9a214a59508c51a05e\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/54/76/37/bfae74b1d9f2b553cb45117a492ba3f567381e4f3ae307b5f6\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=257c7b8cfe7b39db15f6e469e6e416af18fad0d7ce8337846697daa9421dfbaf\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/51/86/5e/aca8b65bdc4038d6012e3bc45c33f438ec33a8582d8f2a7fbb\n",
      "Successfully built pqi docopt\n",
      "Installing collected packages: docopt, pqi\n",
      "Successfully installed docopt-0.6.2 pqi-2.0.6\n",
      "\n",
      "Source is changed to aliyun(https://mirrors.aliyun.com/pypi/simple/).\n",
      "\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.36.1)\n",
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 105kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting lmdb\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/2e/dd/ada2fd91cd7832979069c556607903f274470c3d3d2274e0a848908272e8/lmdb-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (299kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 10.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (6.2.0)\n",
      "Collecting python-Levenshtein\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 33.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (5.1.2)\n",
      "Collecting trdg\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/76/55/4ce0f6e928200d3fe8460638346dcd2916d7aac33c7ebebbfec2b5eb7972/trdg-1.7.0-py3-none-any.whl (91.2MB)\n",
      "\u001b[K     |██████████████████              | 51.5MB 8.1MB/s eta 0:00:055\u001b[?25hCollecting anyconfig\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/b2/44/d8bac632c0ad506933f4b9fd34a495efcc81c01ffdb468dcd0c0f0d4cbab/anyconfig-0.10.1-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 19.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.3.0)\n",
      "Requirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.6.1)\n",
      "Collecting scikit-image>=0.14.2 (from imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
      "\u001b[K     |████████████████████████████████| 29.2MB 7.0MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting Shapely (from imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/98/f8/db4d3426a1aba9d5dfcc83ed5a3e2935d2b1deb73d350642931791a61c37/Shapely-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 11.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.16.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-Levenshtein) (41.4.0)\n",
      "Collecting beautifulsoup4>=4.6.0 (from trdg)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 13.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting diffimg==0.2.3 (from trdg)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/fa/de925a7c2203b52f007ad6b9cce343c21dbe389a221a4f51f25960c83d8b/diffimg-0.2.3.tar.gz\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from trdg) (2.22.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/c0/9b/db2b4777156c755ea589cb93ae50fc12a39119623bd7eca9bb8eaab523fc/tifffile-2021.4.8-py3-none-any.whl (165kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 13.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4MB 10.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4>=4.6.0->trdg)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/36/69/d82d04022f02733bf9a72bc3b96332d360c0c5307096d76f6bb7489f7e57/soupsieve-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.20.0->trdg) (1.25.6)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug) (4.4.0)\n",
      "Building wheels for collected packages: python-Levenshtein, diffimg\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=163159 sha256=820f310458fc0e690b90de7496ed268e14bdd3ec0c04972c6979728666db471c\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/37/32/7f/d1b41ce17eb00f23e152a3da3cb4588e094d55b8f1f7d43159\n",
      "  Building wheel for diffimg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffimg: filename=diffimg-0.2.3-cp37-none-any.whl size=4050 sha256=2f545a744c6a81272b7ada6c8b303310771c394131bcde470c60c5af2fe8b1a1\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/70/b8/cf/783065bf363fd70e7a5a58dafd8b40667db51a8aa9f8935557\n",
      "Successfully built python-Levenshtein diffimg\n",
      "\u001b[31mERROR: scikit-image 0.18.1 has requirement numpy>=1.16.5, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: trdg 1.7.0 has requirement opencv-python>=4.2.0.32, but you'll have opencv-python 4.1.1.26 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: trdg 1.7.0 has requirement pillow>=7.0.0, but you'll have pillow 6.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image, Shapely, imgaug, lmdb, python-Levenshtein, soupsieve, beautifulsoup4, diffimg, trdg, anyconfig\n",
      "Successfully installed PyWavelets-1.1.1 Shapely-1.7.1 anyconfig-0.10.1 beautifulsoup4-4.9.3 diffimg-0.2.3 imgaug-0.4.0 lmdb-1.2.1 python-Levenshtein-0.12.2 scikit-image-0.18.1 soupsieve-2.2.1 tifffile-2021.4.8 trdg-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!mkdir /home/aistudio/external-libraries\r\n",
    "import sys\r\n",
    "sys.path.append('/home/aistudio/external-libraries')\r\n",
    "! pip install tqdm paddlepaddle-gpu==1.7.1.post97 -i https://mirror.baidu.com/pypi/simple\r\n",
    "! pip install pqi\r\n",
    "! pqi use aliyun\r\n",
    "! pip install tqdm imgaug lmdb matplotlib opencv-python Pillow python-Levenshtein PyYAML trdg anyconfig # -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 解压文件\n",
    "\n",
    "压缩包内含训练集图片、训练集图片信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/aistudio/data/data10879')\n",
    "! tar -zxf train_img.tar.gz\n",
    "#! tar -zxf test_img.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 预处理\n",
    "\n",
    "* 文件 langconv(language convert)，这个文件用来把繁体字转成简体字<br>\n",
    "\n",
    "* 函数 read_ims_list：读取train.list文件，生成图片的信息字典\n",
    "* 函数 modify_ch：对标签label进行修改，进行四项操作，分别是“繁体->简体”、“大写->小写”、“删除空格”、“删除符号”。\n",
    "* 函数 pipeline：调用定义的函数，对训练数据进行初步处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class num: 3827\n",
      "训练集数量: 200342, 验证集数量: 10544\n"
     ]
    }
   ],
   "source": [
    "from work.langconv import Converter\n",
    "import codecs\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "os.chdir('/home/aistudio')\n",
    "sys.path.append('/home/aistudio/work')\n",
    "def read_ims_list(path_ims_list):\n",
    "    \"\"\"\n",
    "    读取 train.list 文件\n",
    "    \"\"\"\n",
    "    ims_info_dic = {}\n",
    "    with open(path_ims_list, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=3)\n",
    "            w, h, file, label = parts[0], parts[1], parts[2], parts[3]\n",
    "            ims_info_dic[file] = {'label': label, 'w': int(w)}\n",
    "    return ims_info_dic\n",
    "    \n",
    "\n",
    "def modify_ch(label):\n",
    "    # 繁体 -> 简体\n",
    "    label = Converter(\"zh-hans\").convert(label)\n",
    "\n",
    "    # 大写 -> 小写\n",
    "    label = label.lower()\n",
    "\n",
    "    # 删除空格\n",
    "    label = label.replace(' ', '')\n",
    "\n",
    "    # 删除符号\n",
    "    for ch in label:\n",
    "        if (not '\\u4e00' <= ch <= '\\u9fff') and (not ch.isalnum()):\n",
    "            label = label.replace(ch, '')\n",
    "\n",
    "    return label\n",
    "\n",
    "def save_txt(data, file_path):\n",
    "    \"\"\"\n",
    "    将一个list的数组写入txt文件里\n",
    "    :param data:\n",
    "    :param file_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        data = [data]\n",
    "    with open(file_path, mode='w', encoding='utf8') as f:\n",
    "        f.write('\\n'.join(data))\n",
    "\n",
    "def pipeline(dataset_dir):\n",
    "    path_ims        = pjoin(dataset_dir, \"train_images\")\n",
    "    path_ims_list   = pjoin(dataset_dir, \"train.list\")\n",
    "    path_train_list = pjoin('/home/aistudio/work', \"train.txt\")\n",
    "    path_test_list  = pjoin('/home/aistudio/work', \"test.txt\")\n",
    "    path_label_list = pjoin('/home/aistudio/work', \"dict.txt\")\n",
    "\n",
    "    # 读取数据信息\n",
    "    file_info_dic = read_ims_list(path_ims_list)\n",
    "\n",
    "    # 创建 train.txt\n",
    "    class_set = set()\n",
    "    data_list = []\n",
    "    for file, info in file_info_dic.items():\n",
    "        label = info['label']\n",
    "        label = modify_ch(label)\n",
    "\n",
    "        # 异常: 标签为空\n",
    "        if label == '':\n",
    "            continue\n",
    "\n",
    "        for e in label:\n",
    "            class_set.add(e)\n",
    "        data_list.append(\"{0}\\t{1}\".format(pjoin('/home/aistudio/',path_ims, file), label))\n",
    "        \n",
    "    # 创建 label_list.txt\n",
    "    class_list = list(class_set)\n",
    "    class_list.sort()\n",
    "    print(\"class num: {0}\".format(len(class_list)))\n",
    "    with codecs.open(path_label_list, \"w\", encoding='utf-8') as label_list:\n",
    "        for id, c in enumerate(class_list):\n",
    "            # label_list.write(\"{0}\\t{1}\\n\".format(c, id))\n",
    "            label_list.write(\"{0}\\n\".format(c))\n",
    "\n",
    "    # 随机切分\n",
    "    random.shuffle(data_list)\n",
    "    val_len = int(len(data_list) * 0.05)\n",
    "    val_list = data_list[-val_len:]\n",
    "    train_list = data_list[:-val_len]\n",
    "    print('训练集数量: {}, 验证集数量: {}'.format(len(train_list),len(val_list)))\n",
    "    save_txt(train_list,path_train_list)\n",
    "    save_txt(val_list,path_test_list)\n",
    "    \n",
    "random.seed(0)\n",
    "pipeline(dataset_dir=\"data/data10879\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work/PaddleOCR\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/aistudio/work/PaddleOCR/')\r\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 简要介绍方案\n",
    "\n",
    "**思路介绍**\n",
    "\n",
    "使用PaddleOCR库进行训练和预测\n",
    "\n",
    "**个人方案亮点**\n",
    "\n",
    "在现有的数据中进行 fine-tune，并且正确输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 具体方案分享--trian\n",
    "\n",
    "**大致思路和步骤：**\n",
    "\n",
    "因为最后的评定标准是准确率，所以优选考虑Resnet，常用的是Resnet34结构，所以Backbone选用Resnet34。在阅读PaddleOCR库资料，有表明CTC比Attention具有优势，\n",
    "\n",
    "尤其是对长文本识别，因此Head,Loss选用了CTC模块。Optimizer则选用常用的Adam。\n",
    "\n",
    "**总结：**\n",
    "\n",
    "**Backbone：** Resnet34\n",
    "\n",
    "**Head:** CTC\n",
    "\n",
    "**Loss:** CTC\n",
    "\n",
    "**Optimizer:** Adam\n",
    "\n",
    "由于PaddleOCR集成度、模块化非常的好，因此可以在work/PaddleOCR/configs/rec/rec_r34_vd_none_bilstm_ctc.yml，选择适合比赛所需要的结构，只需要改相对应的参数。\n",
    "\n",
    "大致的框架选择完毕，就进行训练，在训练前期学习率可以选择大一点，到后期的学习率要适当的降低，这是一个常用的提分trick。batch_size可以适当的提高，在AI  \n",
    "studio上，我本想用batch_size：256，但是内存爆了，只好相对于的降低一点。batch_size小了，学习率也要相对应降低一点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 特别说明\n",
    "\n",
    "对于PaddleOCR提供的配置文件rec_r34_vd_none_bilstm_ctc.yml我做出了如下修改\n",
    "\n",
    "1.将epoch_num改为120\n",
    "\n",
    "2.将train_batch_size_per_card改为192(因为GPU限制的原因，本来想改为256，但是爆内存了，就选择了192)\n",
    "\n",
    "3.将test_batch_size_per_card改为128\n",
    "\n",
    "4.将base_lr改为0.00001\n",
    "\n",
    "经测试这样能提高score\n",
    "\n",
    "用https://aistudio.baidu.com/aistudio/projectdetail/681670 作者的预训练权重继续训练，从而得到最优结果。最优预测权重checkpionts放在work/PaddleOCR/output/rec_CRNN_aug_341/best_accuracy。\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-08 11:49:40,272-INFO: {'Global': {'algorithm': 'CRNN', 'use_gpu': True, 'epoch_num': 120, 'log_smooth_window': 20, 'print_batch_step': 100, 'save_model_dir': 'output/rec_CRNN_aug_341', 'save_epoch_step': 1, 'eval_batch_step': 1800, 'train_batch_size_per_card': 192, 'test_batch_size_per_card': 128, 'image_shape': [3, 32, 256], 'max_text_length': 64, 'character_type': 'ch', 'loss_type': 'ctc', 'reader_yml': './configs/rec/rec_icdar15_reader.yml', 'pretrain_weights': '/home/aistudio/work/PaddleOCR/model/latest', 'checkpoints': None, 'save_inference_dir': '/home/aistudio/work/test', 'character_dict_path': '/home/aistudio/work/dict.txt'}, 'Architecture': {'function': 'ppocr.modeling.architectures.rec_model,RecModel'}, 'Backbone': {'function': 'ppocr.modeling.backbones.rec_resnet_vd,ResNet', 'layers': 34}, 'Head': {'function': 'ppocr.modeling.heads.rec_ctc_head,CTCPredict', 'encoder_type': 'rnn', 'SeqRNN': {'hidden_size': 256}}, 'Loss': {'function': 'ppocr.modeling.losses.rec_ctc_loss,CTCLoss'}, 'Optimizer': {'function': 'ppocr.optimizer,AdamDecay', 'base_lr': 1e-05, 'beta1': 0.9, 'beta2': 0.999}, 'TrainReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'num_workers': 8, 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/train.txt'}, 'EvalReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/test.txt'}, 'TestReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'infer_img': '/home/aistudio/work/PaddleOCR/test_images'}}\n",
      "import ujson error: No module named 'ujson' use json\n",
      "2021-05-08 11:49:43,523-INFO: places would be ommited when DataLoader is not iterable\n",
      "W0508 11:49:44.193677   256 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 11.0, Runtime API Version: 9.0\n",
      "W0508 11:49:44.197623   256 device_context.cc:245] device: 0, cuDNN Version: 7.3.\n",
      "2021-05-08 11:49:45,223-INFO: Loading parameters from /home/aistudio/work/PaddleOCR/model/latest...\n",
      "2021-05-08 11:49:46,298-INFO: Finish initing model from /home/aistudio/work/PaddleOCR/model/latest\n",
      "I0508 11:49:46.319135   256 parallel_executor.cc:440] The Program will be executed on CUDA using ParallelExecutor, 1 cards are used, so 1 programs are executed in parallel.\n",
      "I0508 11:49:46.342715   256 build_strategy.cc:365] SeqOnlyAllReduceOps:0, num_trainers:1\n",
      "I0508 11:49:46.372932   256 parallel_executor.cc:307] Inplace strategy is enabled, when build_strategy.enable_inplace = True\n",
      "I0508 11:49:46.387321   256 parallel_executor.cc:375] Garbage collection strategy is enabled, when FLAGS_eager_delete_tensor_gb = 0\n",
      "^C\n",
      "pid 324 terminated, terminate group 255...\n",
      "pid 322 terminated, terminate group 255...\n"
     ]
    }
   ],
   "source": [
    "! export PYTHONPATH=$PYTHONPATH:.\r\n",
    "! python tools/train.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 把比赛的测试集解压到/home/aistudio/work/PaddleOCR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -oq /home/aistudio/external-libraries/test_images.zip -d /home/aistudio/work/PaddleOCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**pyspark包里有包含re.split()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
      "\u001b[K     |████████████████████████████████| 212.3MB 10.5MB/s eta 0:00:01    |██████████████▋                 | 97.2MB 7.6MB/s eta 0:00:16     |█████████████████████           | 138.8MB 11.9MB/s eta 0:00:07     |███████████████████████▋        | 156.9MB 10.7MB/s eta 0:00:06\n",
      "\u001b[?25hCollecting py4j==0.10.9 (from pyspark)\n",
      "\u001b[?25l  Downloading https://mirrors.aliyun.com/pypi/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 11.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767605 sha256=700ba8bab5aeecc38be58bd68db13bfbc542bb8fef88a340be83ee70e0b5e381\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/a2/ed/29/497d35d1af7c0f79fe21a1f38c2a2beded1c92f3fd3863a6bf\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 具体方案分享--test\n",
    "\n",
    "经过几轮训练，Loss稳定了即可拿来进行预测。原作者输出文档存在**2点错误，1.是没有标题。2.预测结果是乱序的。** 进行提交的会出现下图错误。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/67470b8bca974dc8a4c8a888a3140faf69b8ec66c27d437fa862399878da9120)\n",
    "\n",
    "\n",
    "\n",
    "所以要进行必要的修改。对症下药，**第一点.没有标题。我们可以在预测结果输出前，先对预测文档进行写入标题的操作。**\n",
    "\n",
    "因此我们先找到执行预测文件：work/PaddleOCR/tools/infer_rec.py。 我们可以看见此文件第**96行**左右 有`f = open('test2.txt',mode='w',encoding='utf8')`，即创\n",
    "\n",
    "建输出文件并授予可输入的权限。因此我们可以在它的下面进行写入标题的操作：`f.write('new_name\\tvalue\\n')`\n",
    "\n",
    "即\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f14087d2a7374470ac3125c40af544e92b48e80e69db4af78959a2f6bb32818b)\n",
    "\n",
    "这样就解决了第一个错误。\n",
    "\n",
    "\n",
    "\n",
    "第二个错误，是把预测结果变成有序的。**方案有2个：1.是对输入预测图片进行排序后再送入预测。2.是对输出结果的文档进行排序。**\n",
    "\n",
    "**我们优选第一个方案，因为难度比较低，也比较符合操作思维。**\n",
    "\n",
    "我们首先要找出输入预测图片的所在代码。我们可以看到**99-105行**左右是执行了预测操作。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/34eaabf7e42844798f6721cd51c456d3460c58d814344836a619794978b02e4e)\n",
    "\n",
    "\n",
    "\n",
    "我们要特别注意img,img_path这两个参数。它是读取了blobs的参数，我们又转而去看到**85行**左右，它读取了执行test操作，总而言之，应该就是进行test操作。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "接下来留意**87-88行**左右\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7141605c07d04fa5a69c411a65df1275c68a2aff97bc49e08fe54835ecfef1d5)\n",
    "\n",
    "我们可以大致知道它的意思创建了一个List存放了infer_img的路径。**这里有个小窍门，就是我们要善用print函数。** 我们可以把它输出的List给print出来看看，\n",
    "\n",
    "输出看了会发现，**存放的路径居然和预测结果顺序是一样的**，我们也就是找到我们需要修改的地方了。也就是只要我们把存放的路径给整理成有序的，输出的结果\n",
    "\n",
    "就可以符合比赛要求。\n",
    "\n",
    "这是我们就可以用**sort()函数**。因此我们可以再它们后面，**增加一行代码：`infer_list.sort()`**。这时候我们可以执行预测文件查看结果，也可以直接进\n",
    "\n",
    "行print()函数，看存放的路径变得如何了。个人倾向于第二个方案。然后我们发现预测结果顺序变了，变得相对规则了。但是发现从预测结果是\n",
    "0.jpg xxx\n",
    "1.jpg xxx\n",
    "10.jpg xxx\n",
    "11.jpg xxx \n",
    "\n",
    "查了资料发现这是 **因为数字数据类型是字符串，不是整型。因此我们需要把这些数字的类型把字符串转为整型，可以调用int()函数**。\n",
    "\n",
    "但是我们输出存放路径的List发现，数字之前还有一堆路径：/home/aistudio/work/PaddleOCR/test_images并且还有后缀.jpg\n",
    "\n",
    "这时候我们可以**用split函数进行路径的分割**，因为我们要提取中间的数字并进行排序，所以我们要用**调用两次split函数，即re.split(),并用'|'进行分开**。\n",
    "\n",
    "最后把无关的路径和后缀删去，并进行整型转换，便可完成我们的任务。\n",
    "\n",
    "**在89行** 增加下图的代码\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0a77554fea27440e91adee432987dead85e1cf8d786241c8a57fbcb09d7bff94)\n",
    "\n",
    "此时我们可以print查看路径是否已经有序排列了，经查看是有序的，便可执行预测文件，从输出结果来看，我们完成了比赛提交的要求。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0c9e32a254374ecba33716c582d6d01f91618b1cec854ab1bade076f712290ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-20 22:24:32,347-INFO: {'Global': {'algorithm': 'CRNN', 'use_gpu': True, 'epoch_num': 120, 'log_smooth_window': 20, 'print_batch_step': 100, 'save_model_dir': 'output/rec_CRNN_aug_341', 'save_epoch_step': 1, 'eval_batch_step': 1800, 'train_batch_size_per_card': 192, 'test_batch_size_per_card': 128, 'image_shape': [3, 32, 256], 'max_text_length': 64, 'character_type': 'ch', 'loss_type': 'ctc', 'reader_yml': './configs/rec/rec_icdar15_reader.yml', 'pretrain_weights': '/home/aistudio/work/PaddleOCR/output/rec_CRNN_aug_341/best_accuracy', 'checkpoints': 'output/rec_CRNN_aug_341/best_accuracy', 'save_inference_dir': '/home/aistudio/work/test', 'character_dict_path': '/home/aistudio/work/dict.txt'}, 'Architecture': {'function': 'ppocr.modeling.architectures.rec_model,RecModel'}, 'Backbone': {'function': 'ppocr.modeling.backbones.rec_resnet_vd,ResNet', 'layers': 34}, 'Head': {'function': 'ppocr.modeling.heads.rec_ctc_head,CTCPredict', 'encoder_type': 'rnn', 'SeqRNN': {'hidden_size': 256}}, 'Loss': {'function': 'ppocr.modeling.losses.rec_ctc_loss,CTCLoss'}, 'Optimizer': {'function': 'ppocr.optimizer,AdamDecay', 'base_lr': 8e-06, 'beta1': 0.9, 'beta2': 0.999}, 'TrainReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'num_workers': 8, 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/train.txt'}, 'EvalReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'img_set_dir': '/', 'label_file_path': '/home/aistudio/work/test.txt'}, 'TestReader': {'reader_function': 'ppocr.data.rec.dataset_traversal,SimpleReader', 'infer_img': '/home/aistudio/work/PaddleOCR/test_images'}}\n",
      "['ctc_greedy_decoder_0.tmp_0']\n",
      "W0420 22:24:33.271103 12579 device_context.cc:237] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 11.0, Runtime API Version: 9.0\n",
      "W0420 22:24:33.275640 12579 device_context.cc:245] device: 0, cuDNN Version: 7.3.\n",
      "2021-04-20 22:24:36,085-INFO: Finish initing model from output/rec_CRNN_aug_341/best_accuracy\n",
      "100%|█████████████████████████████████████| 10000/10000 [05:12<00:00, 32.03it/s]\n"
     ]
    }
   ],
   "source": [
    "! python3 tools/infer_rec.py -c configs/rec/rec_r34_vd_none_bilstm_ctc.yml -o Global.checkpoints=output/rec_CRNN_aug_341/best_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型应用结果分析\n",
    "\n",
    "**调优参数优化过程分析：** 前期用大的学习率，后期用小的学习率，并且进行相对应的Batch_size调整。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "这是第一次在百度AI studio完整的独立完成比赛，幸运的是获得较好的名次。让我对OCR这一块有了新的认识，也对百度飞桨框架有了初步的认识。\n",
    "\n",
    "在这里要感谢百度飞桨提供训练平台，提供baseline以及优秀的方案供大家进行学习。在这次比赛，我也学到了很多东西，代码能力也进步了一点点。希望百度飞桨可以做的越来越好。\n",
    "\n",
    "**AIStudio提供了AI Studio为选手提供了免费 GPU Tesla V100算力。** 对于硬件资源匮乏的同学来说，这是一个非常棒的平台。\n",
    "\n",
    "最后也期待有更多优秀的作者可以开源他们代码给大家学习。\n",
    "\n",
    "**改进的方向：** \n",
    "\n",
    "**1. 最简单的操作把backbone换成resnet50,resnet101及以上的，更深层次的网络，准确率理论上会更高。**\n",
    "\n",
    "**2. 因为本次比赛预测图片的结果文字不算太长，CTC模块可以尝试换成Attention，可能效果会好一点。**\n",
    "\n",
    "**3.也可以尝试重新把数据进行数据增强，加标签平滑。**\n",
    "\n",
    "**4.可以尝试用模型融合**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨使用体验以及给其他选手学习飞桨的建议\n",
    "\n",
    "这是第一次尝试用飞桨框架完成比赛，平常都是用Pytorch比较多，刚开始接触会有点不习惯，因为它有些细微的文件的差异。并且有少部分执行命令和常用的Linux命令不太一样，需要注意和学习基本操作。但不得不说飞桨框架下的包还是很完善的，比如**PaddleOCR和PaddleDetection**。只需要修改小量参数便可改变网络结构，对于新手来说是非常友好的。\n",
    "\n",
    "所以想给选手学习飞桨的建议：如果是**初学者接触飞桨框架**，建议去官网学习相对应的框架简单的执行命令。官方网站：https://www.paddlepaddle.org.cn/tutorials/projectdetail/695184\n",
    "\n",
    "如果是想用**PaddleOCR**库的可以去这里进行相关的学习：https://www.paddlepaddle.org.cn/tutorials/projectdetail/695184\n",
    "\n",
    "如果是想用**PaddleDetection**库的可以去这里进行相关的学习：https://www.paddlepaddle.org.cn/tutorials/projectdetail/1499121\n",
    "\n",
    "想了解更多的库可以去官方网站进行更多的学习：https://www.paddlepaddle.org.cn/tutorials/projectdetail/695184\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参考资料\n",
    "\n",
    "**PaddleOCR官方资料库**\n",
    "\n",
    "**官网链接：** https://www.paddlepaddle.org.cn/tutorials/projectdetail/695184\n",
    "\n",
    "**GitHub:** https://github.com/PaddlePaddle/PaddleOCR\n",
    "\n",
    "**优秀项目：** https://aistudio.baidu.com/aistudio/projectdetail/681670"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
